{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulating a DRP `Object` Catalog with a Simple Analytic Model\n",
    "\n",
    "_Ji Won Park, Phil Marshall_\n",
    "\n",
    "Created: July 19, 2019 at the LSST DESC hack day\n",
    "\n",
    "Last run: 2019-07-19\n",
    "\n",
    "The goals for this demo notebook are to:\n",
    "\n",
    "* Show what the `Analytic` model class does, and \n",
    "* Check that its outputs are sensible. \n",
    "\n",
    "We'll do this by making an emulated `Object` catalog using a very simple analytic emulator, and making the same plots that we use to evaluate BNN emulator performance. The idea is that the analytic model can serve as the baseline for any ML-based emulator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "For this notebook to run to completion, you will need a copy of the test object dataset, and to have installed the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! curl -o obj_master_tract4850.csv \"https://drive.google.com/file/d/1bEnSJ6YnkWyhXNaQdyjRWE8x3SS6XtVV/view?usp=sharing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting-up\n",
    "\n",
    "We have some standard imports to do, and then the things we need to do in order to use objects from the `torch` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2809)\n",
    "torch.manual_seed(2809)\n",
    "torch.cuda.manual_seed(2809)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device=='cuda':\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emulating an `Object` Catalog\n",
    "\n",
    "The `Analytic` model has the same behavior as the `BNN` models - so we first follow the same steps to get the data in shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.load(open(\"args.txt\"))\n",
    "\n",
    "############\n",
    "# Data I/O #\n",
    "############\n",
    "\n",
    "from derp_data import DerpData\n",
    "import itertools\n",
    "\n",
    "# X base columns\n",
    "truth_cols = list('ugrizy') + ['ra_truth', 'dec_truth', 'redshift', 'star',]\n",
    "truth_cols += ['mag_true_%s_lsst' %bp for bp in 'ugrizy']\n",
    "truth_cols += ['size_bulge_true', 'size_minor_bulge_true', 'ellipticity_1_bulge_true', 'ellipticity_2_bulge_true', 'bulge_to_total_ratio_i']\n",
    "truth_cols += ['size_disk_true', 'size_minor_disk_true', 'ellipticity_1_disk_true', 'ellipticity_2_disk_true',]\n",
    "opsim_cols = ['m5_flux', 'PSF_sigma2', 'filtSkyBrightness_flux', 'airmass', 'n_obs']\n",
    "# Y base columns\n",
    "drp_cols = ['extendedness', 'ra_obs', 'dec_obs', 'Ixx', 'Ixy', 'Iyy', 'IxxPSF', 'IxyPSF', 'IyyPSF', ]\n",
    "drp_cols_prefix = ['cModelFlux_', 'psFlux_']\n",
    "drp_cols_suffix = []\n",
    "#drp_cols_suffix = ['_ext_photometryKron_KronFlux_instFlux', '_base_CircularApertureFlux_70_0_instFlux', \n",
    "drp_cols += [t[0] + t[1] for t in list(itertools.product(drp_cols_prefix, list('ugrizy')))]\n",
    "drp_cols += [t[1] + t[0] for t in list(itertools.product(drp_cols_suffix, list('ugrizy')))]\n",
    "\n",
    "\n",
    "# Define dataset\n",
    "data = DerpData(data_path='raw_data/obj_master_tract4850.csv',\n",
    "    data_path2=None,\n",
    "    X_base_cols=truth_cols + opsim_cols, \n",
    "    Y_base_cols=drp_cols, \n",
    "    args=args, ignore_null_rows=True, save_to_disk=True)\n",
    "if not args['data_already_processed']:\n",
    "    data.export_metadata_for_eval(device_type=device.type)\n",
    "# Read metadata if reading processed data from disk:\n",
    "data_meta = json.load(open(\"data_meta.txt\"))\n",
    "\n",
    "X_cols = data_meta['X_cols']\n",
    "Y_cols = data_meta['Y_cols']\n",
    "train_indices = data_meta['train_indices']\n",
    "val_indices = data_meta['val_indices']\n",
    "X_dim = data_meta['X_dim']\n",
    "Y_dim = data_meta['Y_dim']\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Split train vs. val\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# Define dataloader\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}\n",
    "train_loader = DataLoader(data, batch_size=args['batch_size'], sampler=train_sampler, **kwargs)\n",
    "val_loader = DataLoader(data, batch_size=args['batch_size'], sampler=val_sampler, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the output columns of the catalog we are aiming to emulate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_meta['X_cols']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we instantiate the simple `Analytic` model, and have it predict the output catalog. Note that there is no training: the analytic model has a hard-coded astronomy model for the DRP object properties and their errors. So, we just compute the predicted mean properties and the log variances on them, and pass them both to a sampling function to make the emulated table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import models\n",
    "import solver\n",
    "\n",
    "X_val = data.X[val_indices, :]\n",
    "\n",
    "analytic = models.Analytic()\n",
    "params = analytic(X_val, data_meta)\n",
    "sample = solver.sample(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Analytic` model is very simple, it just adds Gaussian noise to the true parameters according to simple formulae for photometric, astrometric, etc errors. The class docstring contains a brief summary of the formulae used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(models.Analytic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Emulated Catalog\n",
    "\n",
    "Let's compare the observed quantities, from the DRP `Object` table, and our simple emulations of them. Both these quantities are noisy - what we would like is for them to have similar noise properties. Simple scatter plots, of `x_emulated` vs `x_observed` may not be very illuminating; plotting the mean and stdev of `x`, in bins of `x` for both `x_emulated` and `x_observed`, should give more insight."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
